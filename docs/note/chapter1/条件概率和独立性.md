# 条件概率和独立性

在许多随机实验中，我们只对结果在样本空间$\mathcal{C}$的子集$A$中的元素感兴趣。就我们的目的而言，这意味着样本空间实际上是子集$A$。我们现在面临的问题是定义一个概率集函数，将$A$定义为新的样本空间。

概率集函数$P(A)$定义在样本空间$\mathcal{C}$上并且$A$为$\mathcal{C}$的子集，所以$P(A)>0$。我们只考虑结果为$A$中元素的随机实验，本质上，我们将$A$作为样本空间。令$B$为$\mathcal{C}$的另一个子集。相对于新的样本空间$A$，我们希望如何定义事件$B$的概率。一旦定义了，这个概率称为事件$B$的条件概率。这样的条件概率表示为$P(B|A)$。我们以如下的方式定义$P(B|A)$
$$
P(A|A) = 1\text{ and }P(B|A) = P(A\cap B|A)
$$
进一步，从相对频率的观点来看，事件$A$和$A\cap B$相对于样本空间$A$和样本空间$\mathcal{C}$的比值应该是相等的；也就是，我们应该有
$$
\frac{P(A\cap B|A)}{P(A|A)} = \frac{P(A\cap B)}{P(A)}
$$

***

定义1.4.1  (条件概率)：假设$B$和$A$都是事件并且$P(A)>0$。则我们定义在给定$A$下的$B$的条件概率为
$$
P(B|A) = \frac{P(A\cap B)}{P(A)}
$$
另外，我们还有

1. $P(B|A)\ge 0$
2. $P(A|A)=1$
3. $P(\cup_{n=1}^\infty B_n|A_n) = \sum_{n=1}^\infty P(B_n|A)$，假设$B_1,B_2,\cdots$为互斥的事件

性质1和2都是显然的。对于性质3，假设事件序列$B_1,B_2,\cdots$是互斥的。它遵循$(B_n\cap A)\cap (B_m\cap A)=\varnothing, n\neq m$。则我们有
$$
\begin{aligned}
P(\bigcup_{n=1}^\infty B_n|A) &= \frac{P[\bigcup_{n=1}^\infty(B_n\cap A)]}{P(A)}\\
&= \sum_{n=1}^\infty\frac{P[B_n\cap A]}{P(A)}\\
&= \sum_{n=1}^\infty P[B_n|A]
\end{aligned}
$$
从条件概率的定义中，我们发现
$$
P(A\cap B) = P(A)P(B|A)
$$
这个关系通常被称作概率的**乘法规则(multiplication rule)**。

考虑$k$个互斥的和穷举的事件$A_1,A_2,\cdots,A_k$并且$P(A_i)>0,i=1,2,\cdots$，也就是说$A_1,A_2,\cdots,A_k$是$\mathcal{C}$的一个划分。令$B$为另一个事件并且$P(B)>0$。我们有
$$
\begin{aligned}
B &= B\cap (A_1\cap A_2\cap \cdots A_k)\\
&= (B\cap A_1)\cup (B\cap A_2)\cup\cdots\cup(B\cap A_k)
\end{aligned}
$$
因为$B\cap A_i,i = 1,2,\cdots,k$是互斥的，所以
$$
P(B) = P(B\cap A_1) + P(B\cap A_2) + \cdots + P(B\cap A_k)
$$
但是，$P(B\cap A_i) = P(A_i)P(B|A_i), i = 1,2,\cdots,k$，因此
$$
\begin{aligned}
P(B) &= P(A_1)P(B|A_1) + P(A_2)P(B|A_2)+\cdots+P(A_k)P(B|A_k)\\
&= \sum_{i=1}^kP(A_i)P(B|A_i)
\end{aligned}
$$
这个结果被称为**全概率公式(law of total probability)**。

***

定理1.4.1 (贝叶斯)。令$A_1,A_2,\cdots,A_k$为使得$P(A_i)>0$的事件。假设$A_1,A_2,\cdots,A_k$形成了样本空间$\mathcal{C}$的划分。则
$$
P(A_j|B) = \frac{P(A_j)P(B|A_j)}{\sum_{i=1}^kP(A_i)P(B|A_i)}
$$

## 独立性

有时，事件$A$发生的概率并不改变事件$B$发生的概率，也就是，当$P(A)>0$时，
$$
P(B|A) = P(B)
$$
在这种情况下，我们说事件$A$和事件$B$是独立的。进一步，乘法规则变成了
$$
P(A\cap B) = P(A)P(B|A) = P(A)P(B)
$$
这反过来又意味着
$$
P(A|B) = \frac{P(A\cap B)}{P(B)} = \frac{P(A)P(B)}{P(B)} = P(A)
$$
注意，如果$P(A)>0$并且$P(B)>0$，则通过上述的讨论，独立性等价于
$$
P(A\cap B) = P(A)P(B)
$$
因此我们有如下定义

定义1.4.2  令$A$和$B$为两个事件。我们称$A$和$B$是独立的如果$P(A\cap B) = P(A)P(B)$。

如果$A$和$B$独立，那么$A^C$和$B$，$A$和$B^C$，$A^C$和$B^C$都是相互独立的。

根一般地，$n$个事件$A_1,A_2,\cdots,A_n$是**相互独立**的当且仅当对于这些事件中$k$个事件的每一个集合，$2\le k \le n$，并且对于任何排列$d_1,d_2,\cdots,d_k$
$$
P(A_{d_1}\cap A_{d_2}\cap \cdots\cap A_{d_k}) = P(A_{d_1})P(A_{d_2})\cdots P(A_{d_k})
$$
特殊地，如果$A_1,A-2,\cdots,A_n$是相互独立的，则
$$
P(A_1\cap A_2\cap\cdots\cap A_n) = P(A_1)P(A_2)\cdots P(A_n)
$$
还有，与两个集合的情况一样，这些事件及其补集的许多组合都是独立的，比如

1. 事件$A_1^C$和$A_2\cup A_3^C\cup A_4$是独立的
2. 事件$A_1\cup A_2^C$，$A_3^C$和$A_4\cap A_5^C$是相互独立的。

> **两两独立不一定相互独立。**

